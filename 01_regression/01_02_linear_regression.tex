\section{Linear Regression}
\label{sec:Linear_Regression}
$k-$NN methods attempt fo fit the data by
finding the averages at each point in the input space.
That is what linear regression tries to do when
the \textit{best} is measured by average square error.
\begin{equation}
\hat f(x) = Ave (y_i|x_i \in N_k(x)).
\end{equation}
Two approximations are happening here:
\begin{itemize}
\item expectation is approximated by averaging over sample data;
\item conditioning at point x is relaxed to conditioning on some region ``close'' to the target point (See Exc.~\ref{ex:LRcond}, especially the margin note). One can show that as $N,k \rightarrow \infty$
such that $k/N \rightarrow 0$, $\hat f(x) \rightarrow E[Y|X=x]$.
\end{itemize}