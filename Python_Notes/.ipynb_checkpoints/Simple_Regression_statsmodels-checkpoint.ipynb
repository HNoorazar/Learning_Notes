{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36d1106e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3d19c2",
   "metadata": {},
   "source": [
    "# Lesson:\n",
    "\n",
    " - ```sm.OLS``` is the array-based API --> it expects numeric matrices/arrays.\n",
    "\n",
    " - ```ols``` (from ```statsmodels.formula.api```) is the formula-based API --> it expects a formula string, not arrays.\n",
    "\n",
    "And, ANOVA table uses the ols from ```statsmodels.formula.api```:\n",
    "https://www.statsmodels.org/dev/generated/statsmodels.stats.anova.anova_lm.html\n",
    "\n",
    "```result_smf.predict(X)``` from ```smf``` works just like ```result.predict(X)```. The same is true about ```conf_int()```\n",
    "\n",
    "```get_prediction``` works like so:\n",
    "\n",
    "```\n",
    "pred = result.get_prediction([1, x0])\n",
    "ci = pred.summary_frame(alpha=0.05)\n",
    "```\n",
    "\n",
    "or from ```smf```:\n",
    "\n",
    "```\n",
    "new_data = pd.DataFrame({\"opp_rushing_yard\": [x0]})\n",
    "pred = result_smf.get_prediction(new_data)\n",
    "ci = pred.summary_frame(alpha=0.05)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aade70f",
   "metadata": {},
   "source": [
    "## Lets stick to ```smf```\n",
    "\n",
    "## Working with ```smf```\n",
    "\n",
    "Model like so\n",
    "\n",
    "```\n",
    "mpg_model = smf.ols('mpg ~ engine_displacement', data = mpg_df)\n",
    "mpg_result = mpg_model.fit()\n",
    "```\n",
    "\n",
    "- It automatically adds intercept.\n",
    "- ```mpg_result.summary()``` Produces summary that includes CI of coefficients at 95% sigfinicance level\n",
    "- ```sm.stats.anova_lm(mpg_result, typ=2)``` creates analysis-of-variance table\n",
    "- ```mpg_result.conf_int()``` shows the CI from the ```.summary()```\n",
    "- ```mpg_result.conf_int(alpha=0.01)``` shows CI at 99% significance level\n",
    "- RSS can be accessed in 2 ways:\n",
    "  - ```(mpg_result.resid ** 2).sum()```\n",
    "  - ```mpg_anova_tbl.loc[\"Residual\", \"sum_sq\"]```\n",
    "  \n",
    "- To predict at new values of ```x``` we need a dataframe:\n",
    "   - new_data = pd.DataFrame({\"engine_displacement\": [x0]})\n",
    "   - predict_table = mpg_result.get_prediction(new_data)\n",
    "   - The above result is a table with predictions, CIs and PIs.\n",
    "   - ```yhat_tbl.summary_frame(alpha=0.01)```\n",
    "   - Predicted values are obtained by ```yhat_tbl.predicted_mean[0]```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89840977",
   "metadata": {},
   "source": [
    "## Recall: Summary of working with ```smf```\n",
    "\n",
    "Model like so\n",
    "\n",
    "```\n",
    "mpg_model = smf.ols('mpg ~ engine_displacement', data = mpg_df)\n",
    "mpg_result = mpg_model.fit()\n",
    "```\n",
    "\n",
    "- It automatically adds intercept.\n",
    "- ```mpg_result.summary()``` Produces summary that includes CI of coefficients at 95% sigfinicance level\n",
    "- ```sm.stats.anova_lm(mpg_result, typ=2)``` creates analysis-of-variance table\n",
    "- ```mpg_result.conf_int()``` shows the CI from the ```.summary()```\n",
    "- ```mpg_result.conf_int(alpha=0.01)``` shows CI at 99% significance level\n",
    "- RSS can be accessed in 2 ways:\n",
    "  - ```(mpg_result.resid ** 2).sum()```\n",
    "  - ```mpg_anova_tbl.loc[\"Residual\", \"sum_sq\"]```\n",
    "  \n",
    "- To predict at new values of ```x``` we need a dataframe:\n",
    "   - ```new_data = pd.DataFrame({\"engine_displacement\": [x0]})```\n",
    "   - ```predict_table = mpg_result.get_prediction(new_data)```\n",
    "   - The above result is a table with predictions, CIs and PIs.\n",
    "   - ```yhat_tbl.summary_frame(alpha=0.01)```\n",
    "   - Predicted values are obtained by ```yhat_tbl.predicted_mean[0]```\n",
    "   \n",
    "**See them in action [here](https://github.com/HNoorazar/Montgomery_Intro_Linear_Regression_Analysis/blob/main/CH2_SimpleLinearRegression.ipynb)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb12cef",
   "metadata": {},
   "source": [
    "# SkLearn vs statsmodel\n",
    "\n",
    "According to chatGPT: \n",
    "- Sklearn better for ML, pipeline, production, integration. Cross-validation\n",
    "- Statsmodel good for inference.\n",
    "\n",
    "\n",
    "```python\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "pipe = Pipeline([(\"scaler\", StandardScaler()), (\"model\", LinearRegression())])\n",
    "scores = cross_val_score(pipe, X, y, cv=5)\n",
    "pipe.fit(X, y)\n",
    "```\n",
    "\n",
    "**statsmodel for inference**\n",
    "\n",
    "```python\n",
    "X_transformed = pipe.named_steps[\"scaler\"].transform(X)\n",
    "feature_names = X.columns  # or define manually\n",
    "X_df = pd.DataFrame(X_transformed, columns=feature_names)\n",
    "X_df[\"y\"] = y\n",
    "\n",
    "formula = \"y ~ \" + \" + \".join(feature_names)\n",
    "model = smf.ols(formula=formula, data=X_df).fit()\n",
    "print(model.summary())\n",
    "```\n",
    "\n",
    "------------\n",
    "\n",
    "- **robust SE**: What does that mean?: heteroskedasticity-robust standard errors\n",
    "Classical OLS assumes homoskedasticity: all errors have the same variance\n",
    "Keep the same coefficient estimates, but compute heteroskedasticity-robust standard errors\n",
    "\n",
    "```python\n",
    "model = smf.ols(formula=formula, data=X_df).fit(cov_type=\"HC3\")\n",
    "```\n",
    "\n",
    "- interaction and polynomial terms:\n",
    "```python\n",
    "model = smf.ols(\"y ~ x1 + x2 + x1:x2\", data=X_df).fit()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3271502",
   "metadata": {},
   "source": [
    "Sklearn linear regression\n",
    "\n",
    "```python\n",
    "linr = LinearRegression()\n",
    "linr.fit(x_train, y_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9038e46e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13.11 (Conda)",
   "language": "python",
   "name": "py313"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
